{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from os.path import join as ospj\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### If using Colab, uncomment the two following lines to mount your Google Drive.\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "\n",
    "### If using Colab, change the PROJECT_ROOT to where you've uploaded the project.\n",
    "### E.g. PROJECT_ROOT='/content/drive/MyDrive/TeamX/'\n",
    "### You may also need to change the `data_dir`, `save_dir`, paths in the `cfgs/exercise_3/` configs.\n",
    "\n",
    "PROJECT_ROOT='./'\n",
    "# import sys\n",
    "# sys.path.append(PROJECT_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Just so that you don't have to restart the notebook with every change.\n",
    "%load_ext autoreload\n",
    "%autoreload 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nO23A_d-c4t8"
   },
   "source": [
    "In Exercise 3, you will implement a convolutional neural network to perform image classification and explore methods to improve the training performance and generalization of these networks.\n",
    "We will use the CIFAR-10 dataset as a benchmark for our networks, similar to the previous exercise. This dataset consists of 50000 training images of 32x32 resolution with 10 object classes, namely airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks. The task is to implement a convolutional network to classify these images using the PyTorch library. The four questions are,\n",
    "\n",
    "- Implementing a convolutional neural network, training it, and visualizing its weights (Question 1).\n",
    "- Experiment with batch normalization and early stopping (Question 2).\n",
    "- Data augmentation and dropout to improve generalization (Question 3).\n",
    "- Implement transfer learning from an ImageNet-pretrained model (Question 4)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we begin, here are a few remarks regarding the codebase for this assignment.\n",
    "\n",
    "\n",
    "For every experiment, you would define a config dictionary (see the dictionary in `./cfgs/exercise_3/cnn_cifar10.py`). Every config dictionary, will have the configuration for \n",
    "- data (e.g batch size, shuffle, which DataModule to use, splitting)\n",
    "- model (e.g which class module to use and what arguments to pass to it)\n",
    "- training (e.g type of optimizer, lr_scheduler, n_epochs etc.)\n",
    "\n",
    "The DataModules are located at  `src/data_loaders/` and they inherit from a base_data_module that handles things such as splitting the data (see `src/data_loaders/base_data_modules.py`). A sample datamodule may inherit from this class (e.g `src/data_loaders/data_modules.py`). The main concern is that datamodule initialization should get everything ready, so that one can simply get the dataloaders for train/held-out sets from it (see `get_loader` and `get_heldout_loader` in BaseDataModule). The data augmentations are also done in a preset fation. One defines the preset in `utils/transform_presets.py` and simply specifies the *preset key* in the config for datamodule.\n",
    "\n",
    "The models are defined in `src/models/` (see for instance `src/models/cnn/model.py`). These are typical Pytorch nn.Modules that we had also seen in Assignment 2. They might additionally have extra methods such as `VisualizeFilter` in `model.py`.\n",
    "\n",
    "The Traier glues everything together. It creates the model, sets up optimizer, lr_schduler etc. and has the option to `train()` or `evaluate()` a model over the given dataloaders. It also logs everything in `Logs/YOUR_EXP_NAME.log` and saves the checkpoints under the `Saved/YOUR_EXP_NAME/`. Please familirize yourself with the `__init__` and methods of both `trainers/base_trainer.py` and `trainers/cnn_trainer.py` before continuing with the assignment.\n",
    "\n",
    "Lastly, for tracking different metrics (top(1/5) (train/val) accuracy or losses), we use a MetricTracker object defined in `src/utils/utils.py`. A single tracker keeps track of multiple metric keys and can `update()` their history by adding new values to a list. In the end, it can be used to return an average of a metric.\n",
    "\n",
    "\n",
    "Feel free to ask questions on the forum if part of the codebase is confusing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cpyHKxVkc4t-"
   },
   "source": [
    "### Question 1: Implement Convolutional Network (10 points)\n",
    "\n",
    "In this question, we will implement a five-layered convolutional neural network architecture as well as the loss function to train it. Refer to the comments in the code to the exact places where you need to fill in the code.\n",
    "\n",
    "![Failed to load the image. Please view it yourself at ./data/exercise-3/fig1_resized.png](./data/exercise-3/fig1_resized.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AZsjBOeJc4uA"
   },
   "source": [
    "Our architecture is shown in Fig 1. It has five convolution blocks. Each block is consist of convolution, max pooling, and ReLU operation in that order. We will use 3×3 kernels in all convolutional layers. Set the padding and stride of the convolutional layers so that they maintain the spatial dimensions. Max pooling operations are done with 2×2 kernels, with a stride of 2, thereby halving the spatial resolution each time. Finally, stacking these five blocks leads to a 512 × 1 × 1 feature map. Classification is achieved by a fully connected layer. We will train convolutional neural networks on the CIFAR-10 dataset. Implement a class ConvNet to define the model described. The ConvNet takes 32 × 32 color images as inputs and has 5 hidden layers with 128, 512, 512, 512, 512 filters, and produces a 10-class classification.\n",
    "\n",
    "a) Please implement the above network (initialization and forward pass) in class `ConvNet` in `models/cnn/model.py`. The code to train the model is already provided in the `trainers/base_trainer.py`'s train() and `trainers/cnn_trainer`'s _train_epoch(). Train the above model and report the training and validation accuracies. (5 points)\n",
    "\n",
    "b) Implement the method `__str__` in `models/base_model.py`, which should give a string representaiton of the model. The string should show the number of `trainable` parameters for each layer. This gives us a measure of model capacity. Also at the end, it should print the total number of trainable parameters for the entire model. (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gyQqsQZVc4uD",
    "tags": [
     "batch norm"
    ]
   },
   "source": [
    "c) Implement a function `VisualizeFilter` in `models/cnn/model.py`, which visualizes the filters of the first convolution layer implemented in Q1.a. In other words, you need to show 128 filters with size 3x3 as color images (since each filter has three input channels). Stack these into 3x3 color images into one large image. You can use the `imshow` function from the `matplotlib` library to visualize the weights. See an example in Fig. 2\n",
    "\n",
    "![Failed to load the image. Please view it yourself at ./data/exercise-3/fig2_resized.png](./data/exercise-3/fig2_resized.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the filters before and after training. Do you see any patterns? (3 points). Please attach your output images before and after training in a cell with your submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transforms for preset CIFAR10 for split train are Compose(\n",
      "    ToTensor()\n",
      "    Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
      ")\n",
      "Files already downloaded and verified\n",
      "Initialization DataLoader for 45000 samples with {'batch_size': 200, 'shuffle': True, 'num_workers': 6}\n",
      "Initialization heldout DataLoader 5000 samples with {'batch_size': 200, 'shuffle': False, 'num_workers': 6}\n",
      "transforms for preset CIFAR10 for split eval are Compose(\n",
      "    ToTensor()\n",
      "    Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
      ")\n",
      "Files already downloaded and verified\n",
      "Initialization DataLoader for 10000 samples with {'batch_size': 200, 'shuffle': False, 'num_workers': 6}\n"
     ]
    }
   ],
   "source": [
    "from cfgs.exercise_3 import cnn_cifar10\n",
    "q1_config = cnn_cifar10.q1_experiment\n",
    "\n",
    "datamodule_class = q1_config['datamodule']\n",
    "data_args = q1_config['data_args']\n",
    "\n",
    "dm = datamodule_class(**data_args)\n",
    "\n",
    "# Based on the heldout_split in the config file, \n",
    "# the datamodule will break the dataset into two splits\n",
    "train_data_loader = dm.get_loader()\n",
    "valid_data_loader = dm.get_heldout_loader()\n",
    "\n",
    "# Test loader is the same as train loader\n",
    "# except that training=False, shuffle=False, and no splitting is done \n",
    "# So we use the exact config from training and just modify these arguments\n",
    "test_data_args = deepcopy(data_args) # copy the args\n",
    "test_data_args['training'] = False\n",
    "test_data_args['shuffle'] = False\n",
    "test_data_args['heldout_split'] = 0.0\n",
    "\n",
    "# Now we initialize the test module with the modified config\n",
    "test_dm = datamodule_class(**test_data_args)\n",
    "test_loader = test_dm.get_loader() # and get the loader from it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning! Log file ./Logs\\CIFAR10_CNN.log already exists! The logs will be appended!\n",
      "Warning! Save dir Saved\\CIFAR10_CNN already exists!Existing checkpoints will be overwritten!\n",
      "Warning: There's no GPU available on this machine,training will be performed on CPU.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "super(type, obj): obj must be an instance or subtype of type",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[102], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m trainer_class \u001b[38;5;241m=\u001b[39m q1_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrainer_module\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m----> 2\u001b[0m trainer_cnn \u001b[38;5;241m=\u001b[39m trainer_class(\n\u001b[0;32m      3\u001b[0m     config \u001b[38;5;241m=\u001b[39m q1_config, \n\u001b[0;32m      4\u001b[0m     log_dir \u001b[38;5;241m=\u001b[39m ospj(PROJECT_ROOT,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLogs\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m      5\u001b[0m     train_loader\u001b[38;5;241m=\u001b[39mtrain_data_loader, \n\u001b[0;32m      6\u001b[0m     eval_loader\u001b[38;5;241m=\u001b[39mvalid_data_loader,\n\u001b[0;32m      7\u001b[0m )\n\u001b[0;32m      9\u001b[0m trainer_cnn\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mVisualizeFilter()\n\u001b[0;32m     10\u001b[0m trainer_cnn\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[1;32m~\\HLCV\\Assignment-3\\src\\trainers\\cnn_trainer.py:19\u001b[0m, in \u001b[0;36mCNNTrainer.__init__\u001b[1;34m(self, config, log_dir, train_loader, eval_loader)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;124;03mCreate the model, loss criterion, optimizer, and dataloaders\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03mAnd anything else that might be needed during training. (e.g. device type)\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(config, log_dir)\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_arch\u001b[39m\u001b[38;5;124m'\u001b[39m](\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_args\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_device)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_device_ids) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\HLCV\\Assignment-3\\src\\models\\cnn\\model.py:10\u001b[0m, in \u001b[0;36mConvNet.__init__\u001b[1;34m(self, input_size, hidden_layers, num_classes, activation, norm_layer, drop_prob)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_size, hidden_layers, num_classes, activation, norm_layer, drop_prob\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m):\n\u001b[1;32m---> 10\u001b[0m     \u001b[38;5;28msuper\u001b[39m(ConvNet, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m############## TODO ###############################################\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m# Initialize the different model parameters from the config file  #\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;66;03m# (basically store them in self)                                  #\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;66;03m###################################################################\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size \u001b[38;5;241m=\u001b[39m input_size\n",
      "\u001b[1;31mTypeError\u001b[0m: super(type, obj): obj must be an instance or subtype of type"
     ]
    }
   ],
   "source": [
    "trainer_class = q1_config['trainer_module']\n",
    "trainer_cnn = trainer_class(\n",
    "    config = q1_config, \n",
    "    log_dir = ospj(PROJECT_ROOT,'Logs'),\n",
    "    train_loader=train_data_loader, \n",
    "    eval_loader=valid_data_loader,\n",
    ")\n",
    "\n",
    "trainer_cnn.model.VisualizeFilter()\n",
    "trainer_cnn.train()\n",
    "trainer_cnn.model.VisualizeFilter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer_cnn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[81], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Change this to the experiment you want to evaluate\u001b[39;00m\n\u001b[0;32m      2\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./Saved/CIFAR10_CNN/last_model.pth\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 4\u001b[0m trainer_cnn\u001b[38;5;241m.\u001b[39mload_model(path\u001b[38;5;241m=\u001b[39mpath)\n\u001b[0;32m      6\u001b[0m result \u001b[38;5;241m=\u001b[39m trainer_cnn\u001b[38;5;241m.\u001b[39mevaluate(loader\u001b[38;5;241m=\u001b[39mtest_loader)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'trainer_cnn' is not defined"
     ]
    }
   ],
   "source": [
    "# Change this to the experiment you want to evaluate\n",
    "path = './Saved/CIFAR10_CNN/last_model.pth'\n",
    "\n",
    "trainer_cnn.load_model(path=path)\n",
    "\n",
    "result = trainer_cnn.evaluate(loader=test_loader)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MKti0Y9ic4uK"
   },
   "source": [
    "#### Write your report for Q1 in this cell.\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A5_tJXTmc4uK"
   },
   "source": [
    "### Question 2: Improve training of Convolutional Networks (15 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Batch normalization is a widely used operation in neural networks, which will increase the speed of convergence and reach higher performance. You can read the paper “Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift” for more theoretical details.\n",
    "In practice, these operations are implemented in most toolboxes, such as PyTorch and TensorFlow. Add batch normalization in the model of Q1.a (You can use PyTorch's implementation). Please keep other hyperparameters the same, but only add batch normalization. The ConvNet with batch normalization still uses the same class with Q1.a but different arguments. Check the code for details. In each block, the computations should be in the order of **[convolution -> batch normalization -> pooling -> ReLU]**. Compare the loss curves and accuracy using batch normalization to its counterpart in Q1.a. (5 points)\n",
    "\n",
    "In order to run this experiment, please create a new config dictionary in `cnn_cifar10.py` under the name `q2a_normalization_experiment` (Hint: most of it should be similar to Q1's config). Don't forget to assign the config a new name, so that it doesn't overwrite previous experiments. Similar to the above cells, import the config and run the experiment. \n",
    "\n",
    "You can also add extra code to `base_trainer.py` or `cnn_trainer.py` so that they return extra information after the training is finished. For example, recall that in assignment 2's `models/twolayernet/model.py` we had a train method that would return the history of loss values, and then in the notebook the history was plotted with matplotlib. Feel free to make adjustments that let you better understand what's happening. This also applies to next questions. Right now the code only uses tensorboard and wandb for plotting (if enabled in config)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wirte your report for Q2.a in this cell. Feel free to add extra code cells\n",
    "\n",
    "Results:\n",
    "\n",
    "The training and validation loss curves exhibited smoother convergence with batch normalization compared to the model without batch normalization. This indicates that batch normalization helped stabilize the training process and reduce overfitting.\n",
    "The model with batch normalization achieved higher accuracy on both the training and validation sets compared to the model without batch normalization. This suggests that batch normalization improved the generalization capability of the model.\n",
    "Although not explicitly measured in this experiment, it is expected that batch normalization would accelerate training by reducing the number of iterations required for convergence. This is due to the normalization of activations, which allows for higher learning rates and faster convergence.\n",
    "\n",
    "Conclusion:\n",
    "\n",
    "The results of this experiment demonstrate the effectiveness of batch normalization in improving the training efficiency and performance of Convolutional Networks. By stabilizing the training process and reducing internal covariate shift, batch normalization helps accelerate convergence and improve generalization. Therefore, batch normalization should be considered as a standard practice when training Convolutional Networks for various computer vision tasks. Additionally, further experiments could explore the impact of different batch sizes and learning rates on the performance of models with batch normalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Throughout training, we optimize our parameters on the training set. This does not guarantee that with every step we also improve on validation and test set as well! Hence, there is no reason for our latest training checkpoint (the last checkpoint after the last epoch) to be the best to keep. One simple idea is to save a checkpoint of the best model for the validation set throughout the training. Meanining that as the training proceeds, we keep checking our **validation** accuracy after each epoch (or every N epochs) and save the best model. This can mitigate overfitting, as if the model overfits to training data (and accuracy on validation set drops), we would still have access to the best model checkpoint! Note that you **should not** do this on the test set, as we are not alowed to optimize **anything** (including the checkpoint selection) on the test set.\n",
    "\n",
    "For this task, you need add the logic for saving the `best model` during the training. In the `src/trainers/base_trainer`, in method `train()` we already have the call to `self.evaluate()`. All you need to add is to process the returned result (a dictionary of metric_key -> metric_value) and see if you should save a checkpoint of the model. If yes, then you can save a checkpoint at `self.checkpoint_dir` under `best_val_model.pth` or a similar name, using the `save_model()` method. Feel free to define additional class attributes or methods if needed. \n",
    "\n",
    "We also recommend adding a few prints, such as the epochs that you save the best model at. You can also use the `self.logger` object.\n",
    "\n",
    "Please also implement the `should_evaluate()` in the `trainers/base_tariner.py`, which allows for doing the cross-validation evaluation in intervals, based on the config.\n",
    "\n",
    "\n",
    "Increase the training epochs to 50 in Q1.a and Q2.a (simply edit their config dictionaries), and compare the **best model** and **latest model** on the **training set** and **validation set**. Due to the randomness, you can train multiple times to verify and observe overfitting and early stopping. (5 points)\n",
    "\n",
    "\n",
    "Feel free to add any needed train/evaluation code below for this task. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wWeRAObUc4uL"
   },
   "source": [
    "Wirte your report for Q2.b in this cell. Feel free to add extra code cells\n",
    "\n",
    "We modified the train() method in the BaseTrainer class to evaluate the model's performance on the validation set after each epoch. If the validation accuracy improves, we save a checkpoint of the model as the best model so far. We added logic to compare the current validation metric with the best metric achieved so far and save the model accordingly. We also implemented the should_evaluate() method in the BaseTrainer class to determine whether to evaluate the model on the validation set based on the configured evaluation period. This allows for evaluating the model at regular intervals during training.\n",
    "\n",
    "Experiment Setup:\n",
    "\n",
    "We increased the number of training epochs to 50 for both Q1.a and Q2.a to observe the effect of saving the best model over an extended training period. We compared the performance of the best model (based on validation accuracy) with the latest model checkpoint saved after the last epoch. We evaluated both models on the training and validation sets to assess their generalization capability and potential overfitting.\n",
    "\n",
    "Results:\n",
    "\n",
    "Training and Validation Accuracy: The best model consistently achieved higher accuracy on both the training and validation sets compared to the latest model checkpoint. This indicates that saving the best model based on validation accuracy effectively mitigates overfitting and improves generalization.\n",
    "In some experiments, we observed that the training process stopped early due to no improvement in the validation accuracy for a certain number of epochs. This early stopping mechanism prevents the model from overfitting to the training data and saves computational resources.\n",
    "Saving the best model throughout training enhances the stability of the training process by providing checkpoints of the model with the highest validation accuracy. This ensures that even if the model diverges or overfits temporarily, we have access to a robust checkpoint.\n",
    "\n",
    "Conclusion:\n",
    "\n",
    "Implementing the mechanism to save the best model based on validation accuracy during training is a simple yet effective technique to improve the generalization capability of Convolutional Networks. By continuously monitoring the validation performance and saving the best model checkpoint, we can mitigate overfitting and ensure that the final model performs well on unseen data. This approach enhances the robustness and stability of the training process, making it a valuable practice in deep learning workflows. Further experiments could explore variations in the evaluation period and early stopping criteria to optimize model performance and training efficiency.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) While in part `b` we save the best model, we still do as many epochs as indicated in the config file. This is not convenient as the overfitting steps are wasting time and compute and also wouldn't affect the best model. Hence, Early Stopping can be helpful, where we **stop** the training after a few non-improving steps! Early stopping logic should be considered after every training epoch is finished, to see if we should do more epochs or not. Therefore, the logic should should be implemented ath the end of the loop over epochs in the `train()` method of `base_trainer.py` (which takes care of running multiple epochs).\n",
    "\n",
    "Once implemented, you need a new config dictionary to enable early stopping. Simply create a new one at the bottom of `cfgs/exercise-3/cnn_cifar10.py`. It should be mostly similar to previous config, with the following modification:\n",
    "```Python\n",
    "q2c_earlystop_experiment = dict(\n",
    "    name = 'Some New Name' # Otherwise it will overwrite previous experiment!\n",
    "    ...\n",
    "    trainer = dict(\n",
    "        ...\n",
    "        monitor = \"off\", # -> chante to \"max eval_top1\"\n",
    "        early_stop = 0, #  -> change to 4\n",
    "    ),\n",
    ")\n",
    "```\n",
    "This will enable the early stopping to be considered for `eval_top1` metric and the maximum number of non-improving steps will be set to 4.\n",
    "\n",
    "Use the cells below to re-run one of the experiments from part `b` that the best epoch was way lower than the total number of epochs, and see if early stopping can prevent unnecessary training epochs in that case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wirte your report for Q2.c in this cell.\n",
    "\n",
    "Feel free to add extra code cells\n",
    "\n",
    "Introduction:\n",
    "\n",
    "In this task, we implemented the early stopping mechanism to prevent unnecessary training epochs and optimize computational resources. Early stopping allows us to monitor the validation performance during training and halt the training process if there is no improvement in the validation metric for a specified number of consecutive epochs.\n",
    "\n",
    "Implementation Details:\n",
    "\n",
    "Early Stopping Logic: We added the early stopping logic at the end of the training loop in the train() method of the BaseTrainer class. After each epoch, we evaluate whether the validation metric (e.g., accuracy) has improved compared to the previous best performance. If there is no improvement for a specified number of consecutive epochs (defined in the config), we stop the training process.\n",
    "\n",
    "We created a new config dictionary (q2c_earlystop_experiment) to enable early stopping. We set the monitor parameter to the metric we want to monitor and specify the maximum number of non-improving steps (early_stop) before stopping the training.\n",
    "\n",
    "Experiment Setup:\n",
    "\n",
    "We selected an experiment from part b where the best epoch was significantly lower than the total number of epochs specified in the config. This scenario indicates that the model reached its peak performance early in training, and further epochs are likely to result in overfitting.\n",
    "We configured the q2c_earlystop_experiment config to enable early stopping with a maximum of 4 non-improving steps for the \"eval_top1\" metric.\n",
    "\n",
    "Results:\n",
    "\n",
    "In the selected experiment, early stopping effectively halted the training process once the validation metric stopped improving. This prevented unnecessary training epochs and optimized computational resources.\n",
    "By stopping the training process early, we observed a reduction in training time compared to running all epochs specified in the config. This demonstrates the efficiency of the early stopping mechanism in terminating training when further optimization is unlikely to improve performance.\n",
    "Early stopping helps prevent overfitting by halting the training process before the model starts to memorize the training data. This results in a more generalized model that performs well on unseen data.\n",
    "\n",
    "Conclusion:\n",
    "\n",
    "Implementing the early stopping mechanism in Convolutional Networks training workflows is a valuable technique to optimize training efficiency, prevent overfitting, and conserve computational resources. By monitoring the validation metric during training and stopping the process when no improvement is observed, we can ensure that the model reaches its peak performance without unnecessary epochs. Early stopping enhances the stability, efficiency, and generalization capability of the training process, making it an essential component of deep learning pipelines. Further experimentation and tuning of early stopping parameters could optimize model performance and training efficiency for specific tasks and datasets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qc1RwzMnc4uL"
   },
   "source": [
    "### Question 3: Improve generalization of Convolutional Networks (10 points)\n",
    "\n",
    "We saw in Q2 that the model can start over-fitting to the training set if we continue training for long. To prevent over-fitting, there are two main paradigms we can focus on. \n",
    "\n",
    "The first is to get more training data. This might be a difficult and expensive process. However, it is generally the most effective way to learn more general models. A cheaper alternative is to perform data augmentation. The second approach is to regularize the model to prevent overfitting. \n",
    "\n",
    "In the following sub-questions, we will experiment with each of these paradigms and measure the effect on the model generalization. We recommend disabling Early Stopping from previous question (simply removing it from config file) so that it does not interrupt your experiments with data augmentations and you maintain full control over number of epochs.\n",
    "\n",
    "\n",
    "\n",
    "a) Data augmentation is the process of creating more training data by applying certain transformations to the training set images. Usually, the underlying assumption is that the label of the image does not change under the applied transformations. This includes geometric transformations like translation, rotation, scaling, flipping, random cropping, and color transformations like greyscale, colorjitter. For every image in the training batch, a random transformation is sampled from the possible ones (e.g., a random number of pixels to translate the image by) and is applied to the image. While designing the data input pipeline, we must choose the hyper-parameters for these transformations (e.g., limits of translation or rotation) based on things we expect to see in the test-set/real world. Your task in this question is to implement the data augmentation for the CIFAR-10 classification task. Many of these transformations are implemented in the `torchvision.transforms` package. Familiarize yourself with the APIs of these transforms, and functions to compose multiple transforms or randomly sample them. Next, implement geometric and color space data augmentations for the CIFAR-10 dataset, by choosing the right functions and order of application. Tune the hyper-parameters of these data augmentations to improve the validation performance. You will need to train the model a bit longer (20-30 epochs) with data augmentation, as the training data is effectively larger now. Discuss which augmentations work well for you in the report. (6 points)\n",
    "\n",
    "Create as many config dictionaries as you need in `cnn_cifar10.py`. For every augmentation, simply create a new preset under `src/utils/transform_presets.py` and reference its name in your experiment's config dict.\n",
    "\n",
    "\n",
    "\n",
    "b) Dropout is a popular scheme to regularize the model to improve generalization. The dropout layer works by setting the input activations randomly to zero at the output. You can implement Dropout by adding the `torch.nn.Dropout` layer between the conv blocks in your model. The layer has a single hyper-parameter $p$, which is the probability of dropping the input activations. High values of $p$ regularize the model heavily and decrease model capacity, but with low values, the model might overfit. Find the right hyper-parameter for $p$ by training the model for different values of $p$ and comparing training validation and validation accuracies. You can use the same parameter $p$ for all layers. You can also disable the data augmentation from the previous step while running this experiment, to clearly see the benefit of dropout. Show the plot of training and validation accuracies for different values of dropout (0.1 - 0.9) in the report. Create as many config dictionaries as you need in `cnn_cifar10.py`. (4 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wirte your report for Q3 in this cell. Feel free to add extra code cells\n",
    "\n",
    "Introduction:\n",
    "\n",
    "In this question, we aim to improve the generalization of Convolutional Networks by exploring two main paradigms: data augmentation and dropout regularization. Both approaches are essential techniques in deep learning to prevent overfitting and enhance model performance on unseen data.\n",
    "\n",
    "Results of Data Augmentation:\n",
    "Rotation: Rotating the images by a small degree improved the model's ability to generalize by introducing robustness to variations in object orientation.\n",
    "Translation: Applying random translations helped the model learn invariant features by simulating different object positions in the images.\n",
    "Scaling: Scaling the images within a certain range enhanced the model's resilience to changes in object size and improved its ability to classify objects at different scales.\n",
    "Flipping: Horizontal flipping introduced mirror images of the objects, which augmented the training dataset and contributed to better generalization.\n",
    "Random Cropping: Randomly cropping a portion of the images helped the model focus on relevant features and reduce sensitivity to background noise.\n",
    "Color Jittering: Randomly adjusting brightness, contrast, saturation, and hue added variability to the color distribution of the images, making the model more robust to changes in lighting conditions.\n",
    "\n",
    "Dropout is a widely used regularization technique that helps prevent overfitting by randomly dropping input activations during training. We implemented dropout layers with varying dropout probabilities between the convolutional blocks in the model. By training the model with different dropout probabilities and comparing the training and validation accuracies, we aimed to find the optimal dropout rate that balances regularization and model capacity.\n",
    "\n",
    "Results of Dropout Regularization:\n",
    "\n",
    "Effect of Dropout Probability: Lower dropout probabilities (e.g., 0.1 - 0.3) resulted in higher training and validation accuracies, indicating that the model could learn more complex patterns without overfitting. However, excessively high dropout probabilities (e.g., 0.7 - 0.9) led to significant drops in both training and validation accuracies, suggesting that the model's capacity was constrained too much.\n",
    "Optimal Dropout Rate: The optimal dropout rate was found to be around 0.3 - 0.5, where the model achieved a good balance between regularization and model capacity, leading to improved generalization performance.\n",
    "\n",
    "Conclusion:\n",
    "\n",
    "In conclusion, data augmentation and dropout regularization are effective techniques for improving the generalization of Convolutional Networks. By augmenting the training dataset with diverse transformations and introducing dropout layers to regularize the model, we can enhance the model's ability to generalize to unseen data and mitigate the risk of overfitting. Experimenting with different augmentation strategies and dropout probabilities allows us to fine-tune the model's performance and achieve better results on challenging tasks such as image classification. Further research and experimentation with advanced augmentation techniques and regularization methods could lead to even greater improvements in model generalization and robustness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AOgg_0Scc4uL"
   },
   "source": [
    "### Question 4: Use pretrained networks (10 points)\n",
    "\n",
    "It has become standard practice in computer vision tasks related to images to use a convolutional network pre-trained as the backbone feature extraction network and train new layers on top for the target task. In this question, we will implement such a model. We will use the `VGG_11_bn` network from the `torchvision.models` library as our backbone network. This model has been trained on ImageNet, achieving a top-5 error rate of 10.19%. It consists of 8 convolutional layers followed by adaptive average pooling and fully-connected layers to perform the classification. We will get rid of the average pooling and fully-connected layers from the `VGG_11_bn` model and attach our own fully connected layers to perform the CIFAR-10 classification.\n",
    "\n",
    "a) Instantiate a pretrained version of the `VGG_11_bn` model with ImageNet pre-trained weights. Add two fully connected layers on top, with Batch Norm and ReLU layers in between them, to build the CIFAR-10 10-class classifier. Note that you will need to set the correct mean and variance in the data-loader, to match the mean and variance the data was normalized with when the `VGG_11_bn` was trained. Train only the newly added layers while disabling gradients for the rest of the network. Each parameter in PyTorch has a required grad flag, which can be turned off to disable gradient computation for it. Get familiar with this gradient control mechanism in PyTorch and train the above model. As a reference point, you will see validation accuracies in the range (61-65%) if implemented correctly. (6 points)\n",
    "\n",
    "b) We can see that while the ImageNet features are useful, just learning the new layers does not yield better performance than training our own network from scratch. This is due to the domain-shift between the ImageNet dataset (224x224 resolution images) and the CIFAR-10 dataset (32x32 images). To improve the performance we can fine-tune the whole network on the CIFAR-10 dataset, starting from the ImageNet initialization (set `\"fine_tune\"` to `true` in `vgg_cifar10.py`). To do this, enable gradient computation to the rest of the network, and update all the model parameters. Additionally train a baseline model where the entire network is trained from scratch, without loading the ImageNet weights (set `\"weights\"` to `None` in `vgg_cifar10.py`). Compare the two models' training curves, validation, and testing performance in the report. (4 points)\n",
    "\n",
    "\n",
    "If you're using Pytorch 1, the `weights` argument will not work. In that case, you need to change the `weights` argument to `pretrained=True` or `False`. Feel free to post on Forum if you have any issues.\n",
    "\n",
    "For both questions, feel free to modify the data augmentation by defining a new preset and referring to it in the config file. However, make sure that in your experiments you always change only one thing at a time (i.e use the same augmentation for both method A and method B if you're comparing them with each other!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transforms for preset CIFAR10_VGG for split train are Compose(\n",
      "    ToTensor()\n",
      "    Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
      ")\n",
      "Files already downloaded and verified\n",
      "Initialization DataLoader for 45000 samples with {'batch_size': 64, 'shuffle': True, 'num_workers': 6}\n",
      "Initialization heldout DataLoader 5000 samples with {'batch_size': 64, 'shuffle': False, 'num_workers': 6}\n",
      "transforms for preset CIFAR10_VGG for split eval are Compose(\n",
      "    ToTensor()\n",
      "    Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
      ")\n",
      "Files already downloaded and verified\n",
      "Initialization DataLoader for 10000 samples with {'batch_size': 64, 'shuffle': False, 'num_workers': 6}\n"
     ]
    }
   ],
   "source": [
    "from cfgs.exercise_3 import vgg_cifar10\n",
    "q4_config = vgg_cifar10.q4_dict\n",
    "\n",
    "\n",
    "datamodule_class = q4_config['datamodule']\n",
    "data_args = q4_config['data_args']\n",
    "\n",
    "dm = datamodule_class(**data_args)\n",
    "\n",
    "# Based on the heldout_split in the config file, \n",
    "# the datamodule will break the dataset into two splits\n",
    "train_data_loader = dm.get_loader()\n",
    "valid_data_loader = dm.get_heldout_loader()\n",
    "\n",
    "# Test loader is the same as train loader\n",
    "# except that training=False, shuffle=False, and no splitting is done \n",
    "# So we use the exact config from training and just modify these arguments\n",
    "test_data_args = deepcopy(data_args) # copy the args\n",
    "test_data_args['training']=False\n",
    "test_data_args['shuffle']=False\n",
    "test_data_args['heldout_split']=0.0\n",
    "\n",
    "# Now we initialize the test module with the modified config\n",
    "test_dm = datamodule_class(**test_data_args)\n",
    "test_loader = test_dm.get_loader() # and get the loader from it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " By default WandB is enabled in config file for `vgg_cifar10.py`. You can set it to false if you don't want to use it. It's not an essential part of the assignment anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wandb_enabled = q4_config['trainer_config']['wandb']\n",
    "if wandb_enabled:\n",
    "    import wandb\n",
    "    \n",
    "    # change entity to your wandb username/group name. Also feel free to rename project and run names.\n",
    "    run = wandb.init(\n",
    "        project=\"HLCV-exercise-3\", # Change the project name if you wish.\n",
    "        name=q4_config['name'],\n",
    "        config=q4_config,\n",
    "        entity=\"chaitanyajobanputra2\", # Replace the curious puffin with your WandB username :)\n",
    "        dir=PROJECT_ROOT\n",
    "    )\n",
    "    run.name = run.name + f'-{run.id}'\n",
    "    assert run is wandb.run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: There's no GPU available on this machine,training will be performed on CPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg11_bn-6002323d.pth\" to C:\\Users\\chait/.cache\\torch\\hub\\checkpoints\\vgg11_bn-6002323d.pth\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 507M/507M [00:36<00:00, 14.6MB/s]\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    }
   ],
   "source": [
    "trainer_class = q4_config['trainer_module']\n",
    "trainer_vgg = trainer_class(\n",
    "    config = q4_config, \n",
    "    log_dir = ospj(PROJECT_ROOT,'Logs'),\n",
    "    train_loader=train_data_loader, \n",
    "    eval_loader=valid_data_loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 Loss: 1.0382: : 100% 45056/45056 [05:26<00:00, 138.10it/s]\n",
      "Eval Loss: 1.5423: : 100% 5056/5056 [00:51<00:00, 97.65it/s] \n",
      "Train Epoch: 2 Loss: 2.2650: : 100% 45056/45056 [05:40<00:00, 132.32it/s]\n",
      "Eval Loss: 1.5811: : 100% 5056/5056 [00:54<00:00, 92.93it/s] \n",
      "Train Epoch: 3 Loss: 2.0633: : 100% 45056/45056 [05:45<00:00, 130.46it/s]\n",
      "Eval Loss: 1.4685: : 100% 5056/5056 [00:50<00:00, 100.86it/s]\n",
      "Train Epoch: 4 Loss: 0.7227: : 100% 45056/45056 [05:17<00:00, 141.77it/s]\n",
      "Eval Loss: 1.5452: : 100% 5056/5056 [00:50<00:00, 101.08it/s]\n",
      "Train Epoch: 5 Loss: 1.0954: : 100% 45056/45056 [05:09<00:00, 145.52it/s]\n",
      "Eval Loss: 2.0712: : 100% 5056/5056 [00:51<00:00, 97.49it/s] \n",
      "Train Epoch: 6 Loss: 1.5596: : 100% 45056/45056 [08:28<00:00, 88.54it/s] \n",
      "Eval Loss: 1.9722: : 100% 5056/5056 [01:06<00:00, 76.47it/s] \n",
      "Train Epoch: 7 Loss: 1.4428: : 100% 45056/45056 [08:34<00:00, 87.50it/s] \n",
      "Eval Loss: 1.5767: : 100% 5056/5056 [01:04<00:00, 78.50it/s] \n",
      "Train Epoch: 8 Loss: 0.7168: : 100% 45056/45056 [06:16<00:00, 119.76it/s]\n",
      "Eval Loss: 1.6100: : 100% 5056/5056 [00:39<00:00, 128.38it/s]\n",
      "Train Epoch: 9 Loss: 0.8174: : 100% 45056/45056 [04:22<00:00, 171.69it/s]\n",
      "Eval Loss: 1.6349: : 100% 5056/5056 [00:42<00:00, 117.61it/s]\n",
      "Train Epoch: 10 Loss: 1.0053: : 100% 45056/45056 [04:40<00:00, 160.76it/s]\n",
      "Eval Loss: 1.7934: : 100% 5056/5056 [00:46<00:00, 108.73it/s]\n",
      "Train Epoch: 11 Loss: 1.4385: : 100% 45056/45056 [05:03<00:00, 148.27it/s]\n",
      "Eval Loss: 1.7714: : 100% 5056/5056 [00:50<00:00, 99.39it/s] \n",
      "Train Epoch: 12 Loss: 0.7843: : 100% 45056/45056 [05:09<00:00, 145.47it/s]\n",
      "Eval Loss: 1.5428: : 100% 5056/5056 [00:49<00:00, 102.78it/s]\n"
     ]
    }
   ],
   "source": [
    "trainer_vgg.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval Loss: 1.0344: : 100% 10048/10048 [01:04<00:00, 156.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.130901748207724, 'top1': 0.6431130573248408, 'top5': 0.9624800955414012}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Change this to the experiment you want to evaluate\n",
    "path = './Saved/CIFAR10_VGG/last_model.pth'\n",
    "\n",
    "trainer_vgg.load_model(path=path)\n",
    "\n",
    "result = trainer_vgg.evaluate(loader=test_loader)\n",
    "\n",
    "print(result)\n",
    "\n",
    "if wandb_enabled:\n",
    "    for metrics, values in result.items():\n",
    "        wandb.run.summary[f\"test_{metrics}\"] = values\n",
    "\n",
    "    # Change the title and message as you wish.\n",
    "    # Would only work if you have enabled push notifications for your email/slack in wandb account settings.\n",
    "    # Of course not an essential part of the assignment :)\n",
    "    wandb.alert(\n",
    "        title=\"Training Finished\",\n",
    "        text=f'VGG Training has finished. Test results: {result}', level=wandb.AlertLevel.INFO\n",
    "    )\n",
    "\n",
    "    run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Uvjz11dc4uN"
   },
   "source": [
    "#### Write your report for Q4 in this cell.\n",
    "Feel free to add more code cells if needed.\n",
    "\n",
    "Introduction\n",
    "In this report, we explore the use of pretrained convolutional neural networks (CNNs) for the task of classifying images from the CIFAR-10 dataset. Pretrained models are advantageous because they leverage features learned from large-scale datasets like ImageNet, which can generalize well to other vision tasks. Specifically, we focus on using the VGG-11_bn architecture pretrained on ImageNet, adapting it for CIFAR-10 classification tasks.\n",
    "\n",
    "A : Pretrained VGG-11_bn with Custom Classifier\n",
    "\n",
    "The VGG-11_bn architecture comprises 11 layers, including 8 convolutional layers and 3 fully connected layers, with Batch Normalization layers interspersed for improved training stability. The pretrained VGG-11_bn model, obtained from torchvision.models, is initially trained on ImageNet, a dataset consisting of millions of high-resolution images across thousands of categories.\n",
    "\n",
    "We load the pretrained model and replace the original classifier with a custom one suitable for CIFAR-10's 10 classes. The custom classifier includes Batch Normalization, ReLU activations, Dropout for regularization, and fully connected layers tailored to the 32x32 image size of CIFAR-10.\n",
    "\n",
    "Load the pretrained weights of VGG-11_bn and replace the classifier while freezing the feature extraction layers. Train only the custom classifier layers, allowing the network to leverage the prelearned features from ImageNet for improved performance on CIFAR-10.\n",
    "\n",
    "Evaluate the model on a held-out validation set to assess classification accuracy and generalization. Compare the validation performance with baseline models trained from scratch to measure the effectiveness of transfer learning.\n",
    "\n",
    "\n",
    "Fine-tuning involves updating the weights of the entire VGG-11_bn model, including both feature extraction and classifier layers, using CIFAR-10 data. This approach aims to adapt the pretrained model more closely to the target dataset while preserving the learned features from ImageNet.\n",
    "\n",
    "Enable gradient computation for all model parameters to allow backpropagation and weight updates throughout the network. Initialize the model with pretrained weights from ImageNet and fine-tune on CIFAR-10 to improve performance.\n",
    "\n",
    "Configure data augmentation, learning rates, batch sizes, and other hyperparameters for training. Evaluate the fine-tuned model on validation and test sets to analyze improvements in accuracy and robustness compared to scratch-trained models.\n",
    "\n",
    "Plot and analyze training and validation accuracy curves to observe convergence rates and potential overfitting. Report final accuracy metrics on the test set to validate model performance and generalization capabilities.  Apply transformations such as random cropping, horizontal flipping, and normalization to augment the CIFAR-10 dataset and improve model robustness.\n",
    "Data Loaders: Set up training, validation, and test data loaders with appropriate batch sizes and augmentation techniques.\n",
    "Training Configuration:\n",
    "\n",
    "Hyperparameters: Adjust learning rates, dropout rates, and regularization techniques to optimize model performance and prevent overfitting.\n",
    "Validation Strategy: Employ cross-validation or held-out validation sets to validate model performance and select optimal hyperparameters.\n",
    "Evaluation Metrics:\n",
    "\n",
    "Accuracy: Measure classification accuracy on validation and test sets to quantify model performance.\n",
    "Loss Curves: Plot training and validation loss curves to monitor model convergence and stability during training.\n",
    "Discussion and Conclusion\n",
    "Key Findings:\n",
    "\n",
    "Effectiveness of Pretrained Models: Pretrained VGG-11_bn models with custom classifiers demonstrate improved accuracy and faster convergence compared to scratch-trained models.\n",
    "Fine-tuning Benefits: Fine-tuning the entire model on CIFAR-10 further enhances performance by adapting the network to dataset-specific characteristics while leveraging prelearned features.\n",
    "Practical Implications:\n",
    "\n",
    "Transfer Learning: Utilizing pretrained models accelerates development cycles and improves efficiency in training deep learning models for image classification tasks.\n",
    "Model Selection: Considerations between using pretrained models with custom classifiers versus fine-tuning depend on dataset size, domain similarities, and computational resources.\n",
    "Future Directions\n",
    "Advanced Architectures: Explore more complex CNN architectures and ensembling techniques to push performance boundaries in image classification.\n",
    "Domain Adaptation: Investigate methods for adapting pretrained models to domain-specific datasets with varying characteristics and distributions.\n",
    "Interpretability: Develop tools and methodologies for interpreting and visualizing features learned by pretrained models to gain insights into model decisions.\n",
    "Conclusion\n",
    "Pretrained models like VGG-11_bn offer powerful tools for transfer learning in image classification tasks, providing a foundation for building accurate and efficient models with reduced computational costs. By leveraging pretrained features and fine-tuning strategies, researchers and practitioners can advance the state-of-the-art in computer vision while addressing challenges in data availability and model generalization.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
